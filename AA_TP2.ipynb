{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from librosa.display import specshow\n",
    "from time import time\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "#load utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "colab_type": "code",
    "id": "HzuReiKCPnzL",
    "outputId": "c6d552ca-aa23-4fcb-84ed-d4b7b0fc7fa3"
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "from os import path\n",
    "\n",
    "if not path.exists(\"speechcommands\"):\n",
    "    !wget http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz\n",
    "    !mkdir speechcommands\n",
    "    !tar -xf speech_commands_v0.01.tar.gz -C speechcommands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "igceWq3yQiIh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_count: 18620\n",
      "test_count: 2552\n",
      "valid_count: 2494\n"
     ]
    }
   ],
   "source": [
    "# generamos lista con las rutas y nombres de archivo de los digitos\n",
    "numbers_filenames = []\n",
    "\n",
    "to_number =\t{\n",
    "  \"zero\": 0,\n",
    "  \"one\": 1,\n",
    "  \"two\": 3,\n",
    "  \"three\": 3,\n",
    "  \"four\": 4,\n",
    "  \"five\": 5,\n",
    "  \"six\": 6,\n",
    "  \"seven\": 7,\n",
    "  \"eight\": 8,\n",
    "  \"nine\": 9\n",
    "}\n",
    "\n",
    "for i in to_number:\n",
    "    path = 'speechcommands/' + i + '/*.wav'\n",
    "    numbers_filenames.append(glob.glob(path))\n",
    "\n",
    "# guardamos la lista de los conjuntos de test y validación\n",
    "# solo para archivos que referencian a dígitos\n",
    "test_filenames = ['speechcommands/' + e for e in open('speechcommands/testing_list.txt','r').read().splitlines() if e[:e.find('/')] in numbers_folders]\n",
    "valid_filenames = ['speechcommands/' + e for e in open('speechcommands/validation_list.txt','r').read().splitlines() if e[:e.find('/')] in numbers_folders]\n",
    "train_filenames = [e for n in range(10) for e in numbers_filenames[n] if (e not in test_filenames) and (e not in valid_filenames)]\n",
    "\n",
    "print('train_count:' , len(train_filenames))\n",
    "print('test_count:' , len(test_filenames))\n",
    "print('valid_count:' , len(valid_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_elapsed_time(f):\n",
    "    \"\"\"\n",
    "    Decorator.\n",
    "    Execute the function and calculate the elapsed time.\n",
    "    Print the result to the standard output.\n",
    "    \"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        # Start counting.\n",
    "        start_time = time()\n",
    "        # Take the original function's return value.\n",
    "        ret = f(*args, **kwargs)\n",
    "        # Calculate the elapsed time.\n",
    "        elapsed_time = time() - start_time\n",
    "        print(\"Elapsed time: %0.10f seconds.\" % elapsed_time)\n",
    "        return ret\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aABqrO8zSz07"
   },
   "outputs": [],
   "source": [
    "def calculate_features(filename, n_mfcc=12, delta=True, deltadelta=True, energy=True, summary_fn = [np.mean, np.std], summary_names=['mean', 'std']):  \n",
    "  #Abro el archivo:\n",
    "  x, sr = librosa.core.load(filename,sr=None)\n",
    "  \n",
    "  #Calculo MFCCs\n",
    "  features = librosa.feature.mfcc(x,sr=sr,n_mfcc=n_mfcc)\n",
    "\n",
    "  #Calculo energia:\n",
    "  if energy:\n",
    "    energy = librosa.feature.rmse(x)\n",
    "    features = np.concatenate([features,energy])\n",
    "\n",
    "  #Aplico media y desvio estandar por defecto\n",
    "  summary_features = np.concatenate([fn(features,axis=1) for fn in summary_fn])\n",
    "    \n",
    "  #Lo mismo con los delta\n",
    "  if delta:\n",
    "    deltafeatures = np.diff(features)\n",
    "    summary_features = np.concatenate([summary_features,np.concatenate([fn(deltafeatures,axis=1) for fn in summary_fn])])\n",
    "\n",
    "  #Y con los delta de segundo orden\n",
    "  if deltadelta:\n",
    "    deltadeltafeatures = np.diff(features,n=2)\n",
    "    summary_features = np.concatenate([summary_features,np.concatenate([fn(deltadeltafeatures,axis=1) for fn in summary_fn])]) \n",
    "  \n",
    "  summary_features = np.append(summary_features, [to_number[filename.split('/')[1]], filename])\n",
    "\n",
    "  return summary_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_features(filename = '', n_mfcc=12, delta=True, deltadelta=True, energy=True, summary_fn = [np.mean, np.std], summary_names=['mean', 'std']):\n",
    "    feat_names = ['mfcc_{}'.format(i) for i in range(n_mfcc)]\n",
    "    if energy: feat_names = feat_names + ['energy']\n",
    "    feat_names = ['{}_{}'.format(name_i,summ_i) for summ_i in summary_names for name_i in feat_names]\n",
    "    if delta: d_names = ['d{}'.format(name) for name in feat_names]\n",
    "    if deltadelta: dd_names = ['dd{}'.format(name) for name in feat_names]\n",
    "\n",
    "    feat_names = feat_names + d_names + dd_names + ['digit', 'file']\n",
    "\n",
    "    return feat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "@count_elapsed_time\n",
    "def calculate_features_if_needed(filenames, result_filename):\n",
    "    result_path = \"features/\"+result_filename\n",
    "    result = []\n",
    "    if not path.exists(result_path):\n",
    "        print(\"Calculating features for \", len(filenames), \" rows -> \", result_path)\n",
    "        features_names = name_features()\n",
    "        features_data = [calculate_features(x) for x in filenames]\n",
    "        pd.DataFrame(data = features_data, columns = features_names).to_csv(result_path)\n",
    "    \n",
    "    else:\n",
    "        print(\"Loading saved features <- \", result_path)\n",
    "        result = pd.read_csv(result_path)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Obtenemos features  y eliminamos las columnas innecesarias para la predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved features <-  features/test_features.csv\n",
      "Elapsed time: 0.0408360958 seconds.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>digit</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eight</th>\n",
       "      <td>0.100705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>five</th>\n",
       "      <td>0.106191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>four</th>\n",
       "      <td>0.099138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nine</th>\n",
       "      <td>0.101489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>0.097179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seven</th>\n",
       "      <td>0.093652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>six</th>\n",
       "      <td>0.095611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three</th>\n",
       "      <td>0.104624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>0.103448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero</th>\n",
       "      <td>0.097962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     count\n",
       "digit          \n",
       "eight  0.100705\n",
       "five   0.106191\n",
       "four   0.099138\n",
       "nine   0.101489\n",
       "one    0.097179\n",
       "seven  0.093652\n",
       "six    0.095611\n",
       "three  0.104624\n",
       "two    0.103448\n",
       "zero   0.097962"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variables a excluir de la predicción\n",
    "var_exclude = ['file', 'Unnamed: 0']\n",
    "\n",
    "test_features = calculate_features_if_needed(test_filenames, \"test_features.csv\")\n",
    "test_features.drop(var_exclude, axis=1, inplace=True)\n",
    "test_features.head(10)\n",
    "pd.crosstab(index=test_features[\"digit\"], columns=\"count\", normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved features <-  features/valid_features.csv\n",
      "Elapsed time: 0.0354580879 seconds.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>digit</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eight</th>\n",
       "      <td>0.097434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>five</th>\n",
       "      <td>0.097033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>four</th>\n",
       "      <td>0.112269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nine</th>\n",
       "      <td>0.092221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>0.092221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seven</th>\n",
       "      <td>0.105453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>six</th>\n",
       "      <td>0.105052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three</th>\n",
       "      <td>0.099439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>0.094627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero</th>\n",
       "      <td>0.104250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     count\n",
       "digit          \n",
       "eight  0.097434\n",
       "five   0.097033\n",
       "four   0.112269\n",
       "nine   0.092221\n",
       "one    0.092221\n",
       "seven  0.105453\n",
       "six    0.105052\n",
       "three  0.099439\n",
       "two    0.094627\n",
       "zero   0.104250"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validaton_features = calculate_features_if_needed(valid_filenames, \"valid_features.csv\")\n",
    "validaton_features.drop(var_exclude, axis=1, inplace=True)\n",
    "validaton_features.head(10)\n",
    "pd.crosstab(index=validaton_features[\"digit\"], columns=\"count\", normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating features for  18620  rows ->  features/train_features.csv\n"
     ]
    }
   ],
   "source": [
    "train_features = calculate_features_if_needed(train_filenames, \"train_features.csv\")\n",
    "train_features.drop(var_exclude, axis=1, inplace=True)\n",
    "train_features.head(10)\n",
    "pd.crosstab(index=train_features[\"digit\"], columns=\"count\", normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Naive Bayes Modelo 1 -- Sin hiperparametros\n",
    "naive_bayes_1 = GaussianNB()\n",
    "naive_bayes_1.fit(train_features.drop('digit',axis=1).values, train_features.digit.values)\n",
    "predict_nb1 = naive_bayes_1.predict(train_features.drop('digit',axis=1).values)\n",
    "\n",
    "print(\"Accuracy training : {:.3f}\".format(naive_bayes_1.score(train_features.drop('digit',axis=1).values, \n",
    "                                                               train_features.digit.values)))\n",
    "print(\"Accuracy Validación: {:.3f}\".format(naive_bayes_1.score(train_features.drop('digit',axis=1).values, \n",
    "                                                          train_features.digit.values)))\n",
    "\n",
    "print(classification_report(validaton_features.digit.values, predict_nb1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Matriz de Confusión \n",
    "sns.set_context('talk')\n",
    "sns.heatmap(confusion_matrix(validaton_features.digit.values, predict_nb1), annot=True, fmt='g')\n",
    "#sns.set(font_scale=0.2) \n",
    "plt.xlabel('Predit')\n",
    "plt.ylabel('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest [Sin Hiperparametros]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest1 = RandomForestClassifier(n_estimators=450, max_depth=10, bootstrap=False,  random_state=1)\n",
    "#random_forest1 = RandomForestClassifier(random_state=1)\n",
    "random_forest1.fit(train_features.drop('digitnumber',axis=1).values, train_features.digit.values)\n",
    "predict_rf1 = random_forest1.predict(validation_features.drop('digit',axis=1).values)\n",
    "\n",
    "print(\"Accuracy training : {:.3f}\".format(random_forest1.score(train_features.drop('digit',axis=1).values, \n",
    "                                                               train_features.digitnumber.values)))\n",
    "print(\"Accuracy Validación: {:.3f}\".format(random_forest1.score(validation_features.drop('digit',axis=1).values, \n",
    "                                                          validation_features.digitnumber.values)))\n",
    "\n",
    "print(classification_report(validaton_features.digit.values, predict_rf1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probamos Hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Primero unir train & validación (Esto según lo que preguntaron en el documento pero aún no lo tengo claro)\n",
    "to_hiper = train_features.append(validation_features, ignore_index=True)\n",
    "\n",
    "#genero listo con datos a usar en split de validación u entrenamiento -1 para entrenar y 0 para validar\n",
    "test_fold = list([-1] * len(train_features) + [0]*len(validation_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Agrego hiperparametrización \n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score, StratifiedShuffleSplit\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "kfoldcv = PredefinedSplit(test_fold)  ## Indices de Split predefinido de Validacion\n",
    "\n",
    "parametros = {'n_estimators':range(100, 250, 15), 'max_depth':range(6, 12, 2), 'bootstrap':[True, False], 'random_state': range(0, 5, 1)}\n",
    "\n",
    "\n",
    "clf = RandomizedSearchCV(RandomForestClassifier(), parametros, n_jobs=10, random_state=131313,    \n",
    "                         scoring='accuracy', n_iter=3, cv = kfoldcv)\n",
    "\n",
    "### Me genera muchas dudas la data con la que se fitea xq no deberían ser entrenamiento y validación\n",
    "## con esto se está haciendo trampa\n",
    "clf.fit(to_hiper.drop('digit',axis=1).values, to_hiper.digit.values)\n",
    "rf = clf.best_estimator_  \n",
    "\n",
    "print(clf.best_score_, clf.best_params_)\n",
    "print(\"Accuracy training : {:.3f}\".format(rf.score(train_features.drop('digit',axis=1).values, \n",
    "                                                   train_features.digitnumber.values)))\n",
    "print(\"Accuracy Validación: {:.3f}\".format(rf.score(validation_features.drop('digit',axis=1).values, \n",
    "                                                          validation_features.digitnumber.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_mejor = RandomForestClassifier(random_state=4, n_estimators=175, max_depth=10, bootstrap=False)\n",
    "rf_mejor.fit(train_features.drop('digit',axis=1).values, train_features.digit.values)\n",
    "\n",
    "print(\"Accuracy training : {:.3f}\".format(rf.score(train_features.drop('digitn',axis=1).values, \n",
    "                                                   train_features.digit.values)))\n",
    "print(\"Accuracy Validación: {:.3f}\".format(rf.score(validation_features.drop('digit',axis=1).values, \n",
    "                                                          validation_features.digit.values)))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "name": "AA_TP2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
